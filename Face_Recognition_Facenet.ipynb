{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d85717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e22395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing tensorflow\n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f406df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking version\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4bcb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "#Loading Facenet model\n",
    "\n",
    "model = load_model('facenet_keras.h5')# load the model siamese trained model for facial recognition only\n",
    "\n",
    "print(model.inputs)# input is 3Dimensional\n",
    "print(model.outputs) #flatten output is 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac92af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multi-task Cascaded Convolutional Networks (MTCNN) is a framework developed as a solution for  face detection\n",
    "# downloading the library to get bounding boxes around the faces in the images\n",
    "!pip install mtcnn # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e71a146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "# load image from file\n",
    "image = plt.imread('pak_cric_group.jpg')\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bc8461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtcnn.mtcnn import MTCNN\n",
    "detector = MTCNN()\n",
    "# detect faces in the image and storing it in results\n",
    "results = detector.detect_faces(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca93cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results) # 15 persons in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef40451",
   "metadata": {},
   "outputs": [],
   "source": [
    "results #bounding boxes for each face and position of eyes, nose and mouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4034eacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract only face regions we can extract key['box from the results which is a dictionary']\n",
    "faces=[]\n",
    "for i in range(len(results)):\n",
    "    # extract the bounding box from the first face\n",
    "    x1, y1, width, height = results[i]['box']\n",
    "    # bug fix\n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "\n",
    "    # extract the face\n",
    "    face = image[y1:y2, x1:x2]\n",
    "\n",
    "    # resize pixels to the model size\n",
    "    image1 = Image.fromarray(face)\n",
    "    image1 = image1.resize((160, 160))\n",
    "    face_array = np.array(image1)\n",
    "    faces.append(face_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ac3ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b656b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in faces:\n",
    "    plt.imshow(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52e6cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images stored in database as refernce \n",
    "# calling one by one and getting bounding boxes\n",
    "from os import listdir\n",
    "folder = 'Database_pak/'\n",
    "i = 1\n",
    "face_ref=[]\n",
    "# enumerate files\n",
    "for filename in listdir(folder):\n",
    "\n",
    "    path = folder + filename\n",
    "    image = plt.imread(path)\n",
    "    \n",
    "    results = detector.detect_faces(image)\n",
    "    # extract the bounding box from the first face\n",
    "    x1, y1, width, height = results[0]['box']\n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    # extract the face\n",
    "    face = image[y1:y2, x1:x2]\n",
    "    # resize pixels to the model size\n",
    "    image1 = Image.fromarray(face)\n",
    "    image1 = image1.resize((160,160))\n",
    "    face_array = np.array(image1)\n",
    "    face_ref.append(face_array)\n",
    "    \n",
    "    plt.subplot(2, 7, i)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(face)\n",
    "    i += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817e9738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting embedding vector for the images in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404aaba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_ref=[]\n",
    "for i in range(len(face_ref)):\n",
    "    face_pn=face_ref[i].astype('float32')\n",
    "    # standardize pixel values across channels (global)\n",
    "    mean, std = face_pn.mean(), face_pn.std()\n",
    "    face_pn = (face_pn - mean) / std # z score,standard scaler\n",
    "\n",
    "    face_pn = np.expand_dims(face_pn, axis=0)\n",
    "\n",
    "    y_pn = model.predict(face_pn)\n",
    "    # get embedding\n",
    "    embedding_ref = y_pn[0] #128 vector flatten\n",
    "    emb_ref.append(embedding_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7275f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(emb_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a477a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_ref[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f477d408",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=9 #give the index of any player\n",
    "\n",
    "plt.imshow(faces[i]) # Anchor/original face in the group image\n",
    "face_anch=faces[i].astype('float32')\n",
    "# standardize pixel values across channels (global)\n",
    "mean, std = face_anch.mean(), face_anch.std()\n",
    "face_anch = (face_anch - mean) / std\n",
    "\n",
    "face_anch = np.expand_dims(face_anch, axis=0)\n",
    "\n",
    "y_anch = model.predict(face_anch)\n",
    "# get embedding\n",
    "emb_anch = y_anch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680b14bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_anch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee240ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare the embedding of anchor image with reference image\n",
    "res1=[]\n",
    "for i in range(len(emb_ref)):\n",
    "    res1.append(np.sqrt(np.sum((emb_ref[i]-emb_anch)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b154bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5635875",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2009507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9ce419",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(face_ref[np.argmin(res1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb82c212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
